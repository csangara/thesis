kmeancorr= kmeans(tg_rescaled, centers = 100)
datas <- c("tg_rescaled", "data.filtered")
for (data_name in datas){
data <- get(data_name)
breaks.tmp <- seq(min(data,na.rm=TRUE), max(data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data[which(kmeancorr$cluster== 4 ),]), col=bluered(40), scale="none",
density.info='none', trace="none", Colv=FALSE, Rowv=FALSE, dendrogram = 'none',
main=data_name)
}
kmeancorr= kmeans(tg_rescaled, 100)
datas <- c("tg_rescaled", "data.filtered")
for (data_name in datas){
data <- get(data_name)
breaks.tmp <- seq(min(data,na.rm=TRUE), max(data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data[which(kmeancorr$cluster== 4 ),]), col=bluered(40), scale="none",
density.info='none', trace="none", Colv=FALSE, Rowv=FALSE, dendrogram = 'none',
main=data_name)
}
breaks.tmp <- seq(min(data.filtered,na.rm=TRUE), max(data.filtered,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data.filtered [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
data
datas <- c("tg_rescaled", "data.filtered")
data <- get("data.filtered")
breaks.tmp <- seq(min(data.filtered,na.rm=TRUE), max(data.filtered,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data.filtered [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
breaks.tmp <- seq(min(data,na.rm=TRUE), max(data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
for (data_name in datas){
data <- get(data_name)
breaks.tmp <- seq(min(data,na.rm=TRUE), max(data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data[which(kmeancorr$cluster== 4 ),]), col=bluered(40), scale="none",
density.info='none', trace="none", Colv=FALSE, Rowv=FALSE, dendrogram = 'none',
main=data_name)
}
for (data_name in datas){
tmp.data <- get(data_name)
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tmp.data[which(kmeancorr$cluster== 4 ),]), col=bluered(40), scale="none",
density.info='none', trace="none", Colv=FALSE, Rowv=FALSE, dendrogram = 'none',
main=data_name)
}
breaks.tmp <- seq(min(data.filtered,na.rm=TRUE), max(data.filtered,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data.filtered [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
breaks.tmp <- seq(min(data.filtered,na.rm=TRUE), max(data.filtered,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(data.filtered [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tmp.data [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
datas <- c("tg_rescaled", "data.filtered")
kmeancorr= kmeans(tg_rescaled, 100)
datas <- c("tg_rescaled", "data.filtered")
for (data_name in datas){
tmp.data <- get(data_name)
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1))
heatmap.2(as.matrix(tmp.data[which(kmeancorr$cluster== 4 ),]), col=bluered(40), scale="none",
density.info='none', trace="none", Colv=FALSE, Rowv=FALSE, dendrogram = 'none',
main=data_name)
}
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tmp.data [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
kmeancorr= kmeans(tg_rescaled, 100)
datas <- c("tg_rescaled", "data.filtered")
for (data_name in datas){
tmp.data <- get(data_name)
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tmp.data [which(kmeancorr$cluster == 4),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp)
}
kmeancorr= kmeans(tg_rescaled, 100)
datas <- c("tg_rescaled", "data.filtered")
for (data_name in datas){
tmp.data <- get(data_name)
breaks.tmp <- seq(min(tmp.data,na.rm=TRUE), max(tmp.data,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tmp.data [which(kmeancorr$cluster == 4),]), col=bluered(40),
scale="none", density.info='none', trace="none",
Rowv=FALSE, dendrogram = 'none', Colv=FALSE,breaks=breaks.tmp,
main=data_name)
}
ClusterNr=18
indices = which(kmeancorr$cluster ==ClusterNr)
tg_rescaled_t =t(data.filtered)
tg_rescaled_t_selected=tg_rescaled_t[,indices]
k=1:nrow(tg_rescaled_t_selected)
matplot(k, tg_rescaled_t_selected, type ='l', xlab=paste0('Genes in cluster ', ClusterNr) ,ylab =  'Expression')
ClusterNr=18
indices = which(kmeancorr$cluster ==ClusterNr)
tg_rescaled_t =t(data.filtered)
tg_rescaled_t_selected=tg_rescaled_t[,indices]
k=1:nrow(tg_rescaled_t_selected)
matplot(k, tg_rescaled_t_selected, type ='l', xlab=paste0('Genes in cluster ', ClusterNr) ,ylab =  'Expression')
ClusterNr=18
indices = which(kmeancorr$cluster ==ClusterNr)
tg_rescaled_t =t(tg_rescaled)
tg_rescaled_t_selected=tg_rescaled_t[,indices]
k=1:nrow(tg_rescaled_t_selected)
matplot(k, tg_rescaled_t_selected, type ='l', xlab=paste0('Genes in cluster ', ClusterNr) ,ylab =  'Expression')
ClusterNr=92
Names = names.filtered[which(kmeancorr$cluster == ClusterNr)]
ClusterNr=92
Names = rownames(tg_rescaled)[which(kmeancorr$cluster == ClusterNr)]
Names
outputfile = 'test.txt'
write.table(Names,outputfile,sep="\t", quote=FALSE, append=FALSE, col.names=FALSE, row.names=FALSE)
breaks.tmp <- seq(min(data.filtered,na.rm=TRUE), max(data.filtered,na.rm=TRUE), length=(40+1) )
heatmap.2(as.matrix(tg_rescaled[(which(kmeancorr$cluster == ClusterNr)),]), col=bluered(40), scale="none", density.info='none', trace="none",   Rowv=FALSE, Colv=FALSE,breaks=breaks.tmp)
exp(2.092e-01)
exp(1.047e-01)
exp(2.092e-01/1.047e-01)
exp(2.092e-01-1.047e-01)
knitr::opts_chunk$set(echo = TRUE)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install(version = "3.10")
#BiocManager::install("multtest")
#BiocManager::install("gplots")
#BiocManager::install("scatterplot3d")
#BiocManager::install("cluster")
#BiocManager::install("fpc")
#BiocManager::install("rgl")
library(multtest)
library(gplots)
library(rgl)
library(scatterplot3d)
library(cluster)
library(fpc)
install.packages("fpc")
knitr::opts_chunk$set(echo = TRUE)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
#BiocManager::install(version = "3.10")
#BiocManager::install("multtest")
#BiocManager::install("gplots")
#BiocManager::install("scatterplot3d")
#BiocManager::install("cluster")
#BiocManager::install("fpc")
#BiocManager::install("rgl")
library(multtest)
library(gplots)
library(rgl)
library(scatterplot3d)
library(cluster)
library(fpc)
data(golub, package = "multtest")
colnames(golub)<-factor(golub.cl,levels=0:1, labels= c("ALL","AML"))
#rescale
dim(golub)
golub_patients = t(golub)
row_mean = apply(golub_patients, 1, mean, na.rm=TRUE)
golub_meancentered_patients = golub_patients - row_mean
SD = apply(golub_meancentered_patients, 1, sd, na.rm=TRUE)
golub_rescaled_patients = golub_meancentered_patients/SD
dim(golub_rescaled_patients)
SD = apply(golub_rescaled_patients, 1, sd) # should be one
rownames(golub_rescaled_patients)<-factor(golub.cl,levels=0:1, labels= c("ALL","AML"))
#calculate Euclidean distance
d.euclidean_rescaled_patients <- dist(golub_rescaled_patients, method="euclidean")
dim(as.matrix(d.euclidean_rescaled_patients) )
#[1] 38 38
m.patients_rescaled <- as.matrix(d.euclidean_rescaled_patients)
?clusGap
Gap <- clusGap(golub_rescaled_patients,FUN=kmeans,nstart=1,K.max=10,B=600) # Takes a #while
# Note that B=100 is a low number of monte Carlo samples but is done here for speed. #Better would be B= 600.
print(Gap,method= "globalmax")
# number of clusters will be about 3
plot(Gap)
library(cluster)
kmeangolub3_patients <- kmeans(golub_rescaled_patients,2,nstart=100)
kmeangolub3_patients$cluster
?kmeans
kmeangolub2_patients <- kmeans(golub_rescaled_patients,2,nstart=100)
kmeangolub3_patients <- kmeans(golub_rescaled_patients,3,nstart=100)
kmeangolub4_patients <- kmeans(golub_rescaled_patients,4,nstart=100)
kmeangolub5_patients <- kmeans(golub_rescaled_patients,5,nstart=100)
kmeangolub10_patients <- kmeans(golub_rescaled_patients,10,nstart=100)
kmeangolub20_patients <- kmeans(golub_rescaled_patients,20,nstart=100)
?cluster.stats # Shows help file with all calculated stats
cluster.stats2 <- cluster.stats(m.patients_rescaled, kmeangolub2_patients$cluster)
cluster.stats3 <- cluster.stats(m.patients_rescaled, kmeangolub3_patients$cluster)
cluster.stats4 <- cluster.stats(m.patients_rescaled, kmeangolub4_patients$cluster)
cluster.stats5 <- cluster.stats(m.patients_rescaled, kmeangolub5_patients$cluster)
cluster.stats10 <- cluster.stats(m.patients_rescaled, kmeangolub10_patients$cluster)
cluster.stats20 <- cluster.stats(m.patients_rescaled, kmeangolub20_patients$cluster)
cluster.stats2$dunn2 # about 1.106356
cluster.stats3$dunn2 # about 1.060127
cluster.stats4$dunn2 # about 1.068154
cluster.stats5$dunn2 # about 1.07672
cluster.stats10$dunn2 # about 0.9688459
cluster.stats20$dunn2 # about 0.89794
k.list <- c(2:20)
k.list
dunnValues <- lapply(k.list,function (x) cluster.stats(m.patients_rescaled,kmeans(golub_rescaled_patients,x,nstart=100)$cluster)$dunn2)
plot(k.list, dunnValues,xlab="number of clusters k",ylab="dunn2 values")
#OR previous code written less concisely
k.list <- c(2:20)
# Define a function which calculates the dunn2 value for some number of clusters
function_calculate_dunn2_value <- function(x) {
cluster.stats(m.patients_rescaled,kmeans(golub_rescaled_patients,x,nstart=100)$cluster)$dunn2
}
# Apply above function iteratively between 2 and 20 clusters
dunnValues <- lapply(k.list, function_calculate_dunn2_value)
# Plot the results
plot(k.list, dunnValues,xlab="number of clusters k",ylab="dunn2 values")
silhouettes<- cluster.stats(m.patients_rescaled, kmeangolub2_patients$cluster, silhouette = T)
# only outputs the average silhouette coeffients
silhouettes$avg.silwidth
# 0.1080045
# Use silhouette function to
silhouette2 <- silhouette(kmeangolub2_patients$cluster, d.euclidean_rescaled_patients)
silhouette3 <- silhouette(kmeangolub3_patients$cluster, d.euclidean_rescaled_patients)
silhouette4 <- silhouette(kmeangolub4_patients$cluster, d.euclidean_rescaled_patients)
silhouette5 <- silhouette(kmeangolub5_patients$cluster, d.euclidean_rescaled_patients)
silhouette10 <- silhouette(kmeangolub10_patients$cluster,d.euclidean_rescaled_patients)
silhouette2
plot(silhouette2)
plot(silhouette3)
plot(silhouette4)
plot(silhouette5)
plot(silhouette10)
silhouette2
cluster.stats_compare_4_5 <- cluster.stats(m.patients_rescaled, kmeangolub5_patients$cluster, kmeangolub4_patients$cluster,compareonly=T)
cluster.stats_compare_4_5$corrected.rand # should be around 0.7340873
#compareonly parameter: only the corrected rand index is calculated
?cluster.stats
exp(-0.148555)
1/exp(-0.148555)
exp(-0.560906)
1/exp(-0.560906)
exp(-0.94)
exp(-0.21)
exp(-0.071645)
1/exp(-0.071645)
exp(-0.08)
exp(-0.07)
?VariableFeatures
??VariableFeatures
brain <- LoadData("stxBrain", type = "anterior1")
library(Seurat)
library(SeuratData)
n
library(SeuratData)
?read.vsv
?read.csv
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=TRUE, row.names=1)
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=TRUE)
View(tab1)
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=TRUE, col.names=1)
View(tab1)
colnames(tab1)
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=FALSE)
View(tab1)
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=TRUE, row.names=1)
View(tab1)
substr(rownames(tab1), 1, 4)
substr(rownames(tab1), 1, 3)
tab1$group = factor(substr(rownames(tab1), 1, 3))
View(tab1)
shapiro.test(tab1)
shapiro.test(tab1$Protein)
?apply
tab1 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Each-stage-of-amphipod.csv",
header=TRUE, row.names=1)
View(tab1)
apply(tab1, 2, shapiro.test)
apply(tab1, 1, shapiro.test)
apply(tab1, 2, shapiro.test)
qqplot(tab1$Protein)
qqnorm(tab1$Protein)
qqline(tab1$Protein)
qqnorm(tab1)
qqline(tab1$Lipid)
qqnorm(tab1$Lipid)
qqline(tab1$Lipid)
tab2 = read.csv("D:/Other/proofread/p'nan/prox analysis/Proximate-analysis-Biofloc-of-each-carbon-source.csv",
header=TRUE, row.names=1)
View(tab2)
tab2 = tab2[,-ncol(tab2)]
View(tab2)
apply(tab2, 2, shapiro.test)
apply(tab2, 1, shapiro.test)
apply(tab2, 2, shapiro.test)
qqnorm(tab2$Lipid)
qqline(tab2$Lipid)
qqnorm(tab2$Protein)
qqline(tab2$Protein)
library(ggplot2)
View(tab1)
qplot(sample=Protein, data=tab1)
ggplot(tab1, aes(sample=Protein)) + stat_qq() + stat_qq_line()
ggplot(tab1, aes()) + stat_qq() + stat_qq_line() + facet_grid()
ggplot(tab1, aes(sample=Protein)) + stat_qq() + stat_qq_line()
ggplot(tab1, aes(sample=colname)) + stat_qq() + stat_qq_line()
for (colname in colnames(tab1)){
ggplot(tab1, aes(sample=colname)) + stat_qq() + stat_qq_line()
}
for (colname in colnames(tab1)){
print(ggplot(tab1, aes(sample=colname)) + stat_qq() + stat_qq_line())
}
for (colname in colnames(tab1)){
print(ggplot(tab1, aes(sample=tab1[colname])) + stat_qq() + stat_qq_line())
}
for (colname in colnames(tab1)){
print(ggplot(tab1, aes(sample=tab1[,colname])) + stat_qq() + stat_qq_line())
}
par(mfrow=(2,3))
for (colname in colnames(tab1)){
print(ggplot(tab1, aes(sample=tab1[,colname])) + stat_qq() + stat_qq_line()) + title(colname)
}
par(mfrow=c(2,3))
for (colname in colnames(tab1)){
print(ggplot(tab1, aes(sample=tab1[,colname])) + stat_qq() + stat_qq_line()) + title(colname)
}
par(mfrow=c(2,3))
for (colname in colnames(tab1)){
qqnorm(tab1[,colname], main=colname)
qqline(tab1[,colname])
}
par(mfrow=c(2,3))
for (colname in colnames(tab2)){
qqnorm(tab2[,colname], main=colname)
qqline(tab2[,colname])
}
apply(tab1, 2, shapiro.test)
apply(tab2, 2, shapiro.test)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(dplyr)
library(Seurat)
library(patchwork)
# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "../Data/PBMC/filtered_gene_bc_matrices/hg19/")
# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
pbmc
head(pbmc@meta.data)
# The [[ operator can add columns to object metadata. This is a great place to stash QC stats
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
# Visualize QC metrics as a violin plot
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
pbmc <- NormalizeData(pbmc)
# pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)
#
# # Identify the 10 most highly variable genes
# top10 <- head(VariableFeatures(pbmc), 10)
#
# # plot variable features with and without labels
# plot1 <- VariableFeaturePlot(pbmc)
# plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
# plot1
# plot2
all.genes <- rownames(pbmc)
pbmc <- ScaleData(pbmc, features = all.genes)
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
pbmc <- RunPCA(pbmc)
brain <- LoadData("stxBrain", type = "anterior1")
library(Seurat)
library(SeuratData)
library(ggplot2)
library(patchwork)
library(dplyr)
brain <- LoadData("stxBrain", type = "anterior1")
brain <- SCTransform(brain, assay = "Spatial", verbose = FALSE)
brain <- RunPCA(brain, assay = "SCT", verbose = FALSE)
brain <- FindNeighbors(brain, reduction = "pca", dims = 1:30)
brain <- FindClusters(brain, verbose = FALSE)
brain <- RunUMAP(brain, reduction = "pca", dims = 1:30)
p1 <- DimPlot(brain, reduction = "umap", label = TRUE)
p2 <- SpatialDimPlot(brain, label = TRUE, label.size = 3)
p1
p2
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
install.packages("rlang")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("browaeysrobin/synthvisium", auth_token="122ed9a5920d5a893f7e09b9351e2126ac44690a")
devtools::install_github("https://github.com/MarcElosua/SPOTlight")
knitr::opts_chunk$set(
collapse = TRUE,
# comment = "#>",
warning = FALSE,
message = FALSE
)
library(Seurat)
library(synthvisium)
library(dplyr)
seurat_obj_scrnaseq = readRDS(url("https://zenodo.org/record/3260758/files/seurat_obj_scrnaseq_cortex_filtered.rds"))
# scrnaseq data
DimPlot(seurat_obj, group.by = "subclass", label = T)
synthetic_visium_data = generate_synthetic_visium(seurat_obj = seurat_obj, dataset_type = "artificial_diverse_distinct", clust_var = "subclass", n_regions = 5, n_spots_min = 5, n_spots_max = 20, visium_mean = 30000, visium_sd = 8000)
synthetic_visium_data$counts %>% as.matrix() %>% .[1:5,1:5]
synthetic_visium_data$spot_composition %>% .[1:10,]
synthetic_visium_data$relative_spot_composition %>% .[1:10,]
synthetic_visium_data$gold_standard_priorregion %>% head()
synthetic_visium_data$dataset_properties
# scrnaseq data
DimPlot(seurat_obj, group.by = "brain_subregion")
synthetic_visium_data = generate_synthetic_visium(seurat_obj = seurat_obj, dataset_type = "real", clust_var = "subclass", region_var = "brain_subregion" , n_regions = NULL,
n_spots_min = 5, n_spots_max = 20, visium_mean = 20000, visium_sd = 5000)
# seurat_obj = readRDS(url("https://zenodo.org/record/4072975/files/seurat_obj_scrnaseq_cortex_filtered.rds")) # direct read from URL - will take a long time
# seurat_obj = readRDS(path/seurat_obj_scrnaseq_cortex_filtered.rds")) # after downloading and saving locally
synthetic_visium_data = generate_synthetic_visium(seurat_obj = seurat_obj, dataset_type = "real_top2_overlap", clust_var = "subclass", region_var = "brain_subregion" , n_regions = NULL,
n_spots_min = 50, n_spots_max = 200, visium_mean = 20000, visium_sd = 5000)
possible_dataset_types = c("real", "real_top1","real_top1_uniform","real_top2_overlap","real_top2_overlap_uniform", "real_missing_celltypes_visium", "artificial_uniform_distinct", "artificial_diverse_distinct",  "artificial_uniform_overlap", "artificial_diverse_overlap", "artificial_dominant_celltype_diverse", "artificial_partially_dominant_celltype_diverse", "artificial_missing_celltypes_visium")
devtools::install_github("https://github.com/MarcElosua/SPOTlight")
R_REMOTES_NO_ERRORS_FROM_WARNINGS
?options
?Sys.getenv
Sys.getenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS)
Sys.getenv("R_REMOTES_NO_ERRORS_FROM_WARNINGS")
Sys.getenv("R_REMOTES_NO_ERRORS_FROM_WARNING")
Sys.setenv("R_REMOTES_NO_ERRORS_FROM_WARNING") = TRUE
R_REMOTES_NO_ERRORS_FROM_WARNINGS="true"
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNING)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS)
?Sys.setenv
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS="true")
devtools::install_github("https://github.com/MarcElosua/SPOTlight")
knitr::opts_chunk$set(echo = TRUE)
#Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS="true")
#install.packages("Seurat")
#install.packages("scatterpie")
library(SPOTlight)
library(Seurat)
library(dplyr)
#devtools::install_github('satijalab/seurat-data')
library(SeuratData)
# This file loads single cell experiment objects
cortex_sc <- readRDS("../rds/allen_cortex_dwn.rds")
cortex_sc <- Seurat::SCTransform(cortex_sc, verbose = FALSE)
cortex_sc <- Seurat::RunPCA(cortex_sc, verbose = FALSE)
cortex_sc <- Seurat::RunUMAP(cortex_sc, dims = 1:30, verbose = FALSE, umap.method = 'uwot')
cortex_sc <- Seurat::FindNeighbors(cortex_sc, dims = 1:30, verbose = FALSE)
cortex_sc <- Seurat::FindClusters(cortex_sc, verbose = FALSE)
# InstallData("stxBrain")
anterior <- LoadData("stxBrain", type = "anterior1")
anterior <- Seurat::SCTransform(anterior, assay = "Spatial", verbose = FALSE)
anterior <- Seurat::RunPCA(anterior, verbose = FALSE)
anterior <- Seurat::RunUMAP(anterior, dims = 1:30, verbose = FALSE, umap.method = 'uwot')
anterior <- Seurat::FindNeighbors(anterior, dims = 1:30, verbose = FALSE)
anterior <- Seurat::FindClusters(anterior, verbose = FALSE)
Seurat::DimPlot(cortex_sc, group.by = "subclass")
Seurat::SpatialPlot(anterior)
devtools::install_github("dmcable/RCTD", build_vignettes = TRUE)
browseVignettes('RCTD')
library(RCTD)
library(Matrix)
refdir <- system.file("extdata",'Reference/Vignette',package = 'RCTD') #directory for the reference
reference <- dgeToSeurat(refdir)
View(reference)
datadir <- system.file("extdata",'SpatialRNA/Vignette',package = 'RCTD') # directory for sample Slide-seq dataset
puck <- read.SpatialRNA(datadir) # read in the SpatialRNA object
barcodes <- colnames(puck@counts) #pixels to be used (a list of barcode names).
# This list can be restricted if you want to crop the puck e.g.
# puck <- restrict_puck(puck, barcodes) provides a basic plot of the nUMI of each pixel
# on the plot:
plot_puck_continuous(puck, barcodes, puck@nUMI, ylimit = c(0,round(quantile(puck@nUMI,0.9))),
title ='plot of nUMI')
myRCTD <- create.RCTD(puck, reference, max_cores = 1)
myRCTD <- run.RCTD(myRCTD, doublet_mode = TRUE)
results <- myRCTD@results
# normalize the cell type proportions to sum to 1.
norm_weights = sweep(results$weights, 1, rowSums(results$weights), '/')
cell_type_names <- myRCTD@cell_type_info$info[[2]] #list of cell type names
spatialRNA <- myRCTD@spatialRNA
resultsdir <- 'RCTD_Plots' ## you may change this to a more accessible directory on your computer.
dir.create(resultsdir)
# make the plots
# Plots the confident weights for each cell type as in full_mode (saved as
# 'results/cell_type_weights_unthreshold.pdf')
plot_weights(cell_type_names, spatialRNA, resultsdir, norm_weights)
# Plots all weights for each cell type as in full_mode. (saved as
# 'results/cell_type_weights.pdf')
plot_weights_unthreshold(cell_type_names, spatialRNA, resultsdir, norm_weights)
# Plots the weights for each cell type as in doublet_mode. (saved as
# 'results/cell_type_weights_doublets.pdf')
plot_weights_doublet(cell_type_names, spatialRNA, resultsdir, results$weights_doublet,
results$results_df)
# Plots the number of confident pixels of each cell type in 'full_mode'. (saved as
# 'results/cell_type_occur.pdf')
plot_cond_occur(cell_type_names, resultsdir, norm_weights, spatialRNA)
# makes a map of all cell types, (saved as
# 'results/all_cell_types.pdf')
plot_all_cell_types(results$results_df, spatialRNA@coords, cell_type_names, resultsdir)
# doublets
#obtain a dataframe of only doublets
doublets <- results$results_df[results$results_df$spot_class == "doublet_certain",]
# Plots all doublets in space (saved as
# 'results/all_doublets.pdf')
plot_doublets(spatialRNA, doublets, resultsdir, cell_type_names)
# Plots all doublets in space for each cell type (saved as
# 'results/all_doublets_type.pdf')
plot_doublets_type(spatialRNA, doublets, resultsdir, cell_type_names)
# a table of frequency of doublet pairs
doub_occur <- table(doublets$second_type, doublets$first_type)
# Plots a stacked bar plot of doublet ocurrences (saved as
# 'results/doublet_stacked_bar.pdf')
plot_doub_occur_stack(doub_occur, resultsdir, cell_type_names)
# get a SpatialRNA object that has single cell types, each with a spatial coordinate and RNA
# counts.
puck_d <- get_decomposed_data(results$results_df, myRCTD@internal_vars$gene_list_reg, spatialRNA, results$weights_doublet,
myRCTD@cell_type_info$renorm)
library(SeuratDisk)
path <- "D:/Work (Yr 2 Sem 1)/Thesis/"
setwd("D:/Work (Yr 2 Sem 1)/Thesis/Scripts")
seurat_obj =  readRDS(paste0(path, "rds/allen_cortex_dwn.rds"))
Convert(seurat_obj, to = "h5ad")
devtools::install_github(repo = 'hhoeflin/hdf5r')
